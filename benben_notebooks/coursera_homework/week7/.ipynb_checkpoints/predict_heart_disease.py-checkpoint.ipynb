{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import collections\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from matplotlib import pylab\n",
    "from six.moves import range\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data\n",
    "url = 'https://raw.githubusercontent.com/chiphuyen/tf-stanford-tutorials/master/data/'\n",
    "\n",
    "def maybe_download(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        filename, _ = urlretrieve(url + filename, filename)\n",
    "    statinfo = os.stat(filename)\n",
    "    return filename\n",
    "\n",
    "filename = maybe_download('heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(415, 9)\n",
      "(47, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbp</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>ldl</th>\n",
       "      <th>adiposity</th>\n",
       "      <th>famhist</th>\n",
       "      <th>typea</th>\n",
       "      <th>obesity</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>415.000000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>415.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.007716</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.003536</td>\n",
       "      <td>0.006372</td>\n",
       "      <td>0.001294</td>\n",
       "      <td>-0.006021</td>\n",
       "      <td>-0.005245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.170554</td>\n",
       "      <td>0.150793</td>\n",
       "      <td>0.145453</td>\n",
       "      <td>0.218390</td>\n",
       "      <td>0.492798</td>\n",
       "      <td>0.148035</td>\n",
       "      <td>0.132303</td>\n",
       "      <td>0.158801</td>\n",
       "      <td>0.297527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.319033</td>\n",
       "      <td>-0.116527</td>\n",
       "      <td>-0.262044</td>\n",
       "      <td>-0.522146</td>\n",
       "      <td>-0.584416</td>\n",
       "      <td>-0.616983</td>\n",
       "      <td>-0.355838</td>\n",
       "      <td>-0.115799</td>\n",
       "      <td>-0.567674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.122452</td>\n",
       "      <td>-0.114444</td>\n",
       "      <td>-0.100023</td>\n",
       "      <td>-0.158790</td>\n",
       "      <td>-0.584416</td>\n",
       "      <td>-0.078521</td>\n",
       "      <td>-0.094859</td>\n",
       "      <td>-0.113285</td>\n",
       "      <td>-0.241143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.036982</td>\n",
       "      <td>-0.052425</td>\n",
       "      <td>-0.025807</td>\n",
       "      <td>0.019392</td>\n",
       "      <td>0.415584</td>\n",
       "      <td>0.013786</td>\n",
       "      <td>-0.007657</td>\n",
       "      <td>-0.071366</td>\n",
       "      <td>0.024163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.074130</td>\n",
       "      <td>0.056550</td>\n",
       "      <td>0.073845</td>\n",
       "      <td>0.165126</td>\n",
       "      <td>0.415584</td>\n",
       "      <td>0.106094</td>\n",
       "      <td>0.081113</td>\n",
       "      <td>0.039341</td>\n",
       "      <td>0.248653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.680967</td>\n",
       "      <td>0.883473</td>\n",
       "      <td>0.737956</td>\n",
       "      <td>0.477854</td>\n",
       "      <td>0.415584</td>\n",
       "      <td>0.383017</td>\n",
       "      <td>0.644162</td>\n",
       "      <td>0.871293</td>\n",
       "      <td>0.432326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sbp     tobacco         ldl   adiposity     famhist       typea  \\\n",
       "count  415.000000  415.000000  415.000000  415.000000  415.000000  415.000000   \n",
       "mean    -0.007716    0.001157    0.001615    0.000246    0.003536    0.006372   \n",
       "std      0.170554    0.150793    0.145453    0.218390    0.492798    0.148035   \n",
       "min     -0.319033   -0.116527   -0.262044   -0.522146   -0.584416   -0.616983   \n",
       "25%     -0.122452   -0.114444   -0.100023   -0.158790   -0.584416   -0.078521   \n",
       "50%     -0.036982   -0.052425   -0.025807    0.019392    0.415584    0.013786   \n",
       "75%      0.074130    0.056550    0.073845    0.165126    0.415584    0.106094   \n",
       "max      0.680967    0.883473    0.737956    0.477854    0.415584    0.383017   \n",
       "\n",
       "          obesity     alcohol         age  \n",
       "count  415.000000  415.000000  415.000000  \n",
       "mean     0.001294   -0.006021   -0.005245  \n",
       "std      0.132303    0.158801    0.297527  \n",
       "min     -0.355838   -0.115799   -0.567674  \n",
       "25%     -0.094859   -0.113285   -0.241143  \n",
       "50%     -0.007657   -0.071366    0.024163  \n",
       "75%      0.081113    0.039341    0.248653  \n",
       "max      0.644162    0.871293    0.432326  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre-treatment\n",
    "raw_data = pd.read_csv('heart.csv')\n",
    "\n",
    "label = raw_data['chd']\n",
    "\n",
    "data = raw_data.loc[:,raw_data.columns[:9]].replace(['Present', 'Absent'],[0, 1])\n",
    "data = data.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)), axis=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.10, random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "X_train.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbp</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>ldl</th>\n",
       "      <th>adiposity</th>\n",
       "      <th>famhist</th>\n",
       "      <th>typea</th>\n",
       "      <th>obesity</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>age</th>\n",
       "      <th>chd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>320.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>320.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.009760</td>\n",
       "      <td>0.019157</td>\n",
       "      <td>0.006482</td>\n",
       "      <td>0.007899</td>\n",
       "      <td>-0.056291</td>\n",
       "      <td>0.004075</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.008169</td>\n",
       "      <td>0.030158</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.184933</td>\n",
       "      <td>0.161794</td>\n",
       "      <td>0.149404</td>\n",
       "      <td>0.217209</td>\n",
       "      <td>0.499990</td>\n",
       "      <td>0.153794</td>\n",
       "      <td>0.137875</td>\n",
       "      <td>0.177483</td>\n",
       "      <td>0.294491</td>\n",
       "      <td>0.500783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.319033</td>\n",
       "      <td>-0.116527</td>\n",
       "      <td>-0.262044</td>\n",
       "      <td>-0.522146</td>\n",
       "      <td>-0.584416</td>\n",
       "      <td>-0.616983</td>\n",
       "      <td>-0.355838</td>\n",
       "      <td>-0.115799</td>\n",
       "      <td>-0.567674</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.109631</td>\n",
       "      <td>-0.103707</td>\n",
       "      <td>-0.094796</td>\n",
       "      <td>-0.151657</td>\n",
       "      <td>-0.584416</td>\n",
       "      <td>-0.093906</td>\n",
       "      <td>-0.098702</td>\n",
       "      <td>-0.113285</td>\n",
       "      <td>-0.200327</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.036982</td>\n",
       "      <td>-0.028707</td>\n",
       "      <td>-0.022671</td>\n",
       "      <td>0.030721</td>\n",
       "      <td>0.415584</td>\n",
       "      <td>0.013786</td>\n",
       "      <td>-0.008912</td>\n",
       "      <td>-0.062704</td>\n",
       "      <td>0.064979</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.099771</td>\n",
       "      <td>0.075780</td>\n",
       "      <td>0.074019</td>\n",
       "      <td>0.168903</td>\n",
       "      <td>0.415584</td>\n",
       "      <td>0.106094</td>\n",
       "      <td>0.077114</td>\n",
       "      <td>0.051468</td>\n",
       "      <td>0.289469</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.680967</td>\n",
       "      <td>0.883473</td>\n",
       "      <td>0.737956</td>\n",
       "      <td>0.477854</td>\n",
       "      <td>0.415584</td>\n",
       "      <td>0.383017</td>\n",
       "      <td>0.644162</td>\n",
       "      <td>0.884201</td>\n",
       "      <td>0.432326</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sbp     tobacco         ldl   adiposity     famhist       typea  \\\n",
       "count  320.000000  320.000000  320.000000  320.000000  320.000000  320.000000   \n",
       "mean     0.009760    0.019157    0.006482    0.007899   -0.056291    0.004075   \n",
       "std      0.184933    0.161794    0.149404    0.217209    0.499990    0.153794   \n",
       "min     -0.319033   -0.116527   -0.262044   -0.522146   -0.584416   -0.616983   \n",
       "25%     -0.109631   -0.103707   -0.094796   -0.151657   -0.584416   -0.093906   \n",
       "50%     -0.036982   -0.028707   -0.022671    0.030721    0.415584    0.013786   \n",
       "75%      0.099771    0.075780    0.074019    0.168903    0.415584    0.106094   \n",
       "max      0.680967    0.883473    0.737956    0.477854    0.415584    0.383017   \n",
       "\n",
       "          obesity     alcohol         age         chd  \n",
       "count  320.000000  320.000000  320.000000  320.000000  \n",
       "mean     0.000074    0.008169    0.030158    0.500000  \n",
       "std      0.137875    0.177483    0.294491    0.500783  \n",
       "min     -0.355838   -0.115799   -0.567674    0.000000  \n",
       "25%     -0.098702   -0.113285   -0.200327    0.000000  \n",
       "50%     -0.008912   -0.062704    0.064979    0.500000  \n",
       "75%      0.077114    0.051468    0.289469    1.000000  \n",
       "max      0.644162    0.884201    0.432326    1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#重组数据集，保证label数量相等\n",
    "one_label_result = all_data[(all_data.chd == 1)]\n",
    "zero_label_result = all_data[(all_data.chd == 0)]\n",
    "\n",
    "one_label_length = len(one_label_result)\n",
    "zero_label_length = len(zero_label_result)\n",
    "\n",
    "small_len = one_label_length if one_label_length < zero_label_length else zero_label_length;\n",
    "\n",
    "\n",
    "one_index = random.sample(list(one_label_result.index.values), small_len)\n",
    "zero_index = random.sample(list(zero_label_result.index.values), small_len)\n",
    "\n",
    "new_data = pd.concat([one_label_result.ix[one_index], zero_label_result.ix[zero_index]])\n",
    "new_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288, 9) (288,)\n",
      "(32, 9) (32,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# 数据分10份，拿一份做测试集，九份做训练集\n",
    "train_data_size = int(small_len * 2 * 0.9)\n",
    "test_data_size = int(small_len * 2 * 0.1)\n",
    "\n",
    "train_data_index = random.sample(list(new_data.index.values), train_data_size)\n",
    "train_data = new_data.ix[train_data_index]\n",
    "\n",
    "test_data_index = list(set(new_data.index.values).difference(set(train_data_index)))\n",
    "test_data = new_data.ix[test_data_index]\n",
    "\n",
    "train_label = train_data['chd']\n",
    "train_data = train_data.loc[:,raw_data.columns[:9]]\n",
    "\n",
    "test_label = test_data['chd']\n",
    "test_data = test_data.loc[:,raw_data.columns[:9]]\n",
    "print(train_data.shape, train_label.shape)\n",
    "print(test_data.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paramaters for the model\n",
    "learning_rate = 0.01\n",
    "batch_size = 5\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'to_one_hotting' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-289c32d7325d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mY_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mY_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_one_hotting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mY_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss_batch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'to_one_hotting' is not defined"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(dtype = np.float32, shape = [9, None], name='X')\n",
    "Y = tf.placeholder(dtype = np.float32, shape = [1, None], name='Y')\n",
    "\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "# W1 = tf.random_normal([12, 9], dtype=tf.float32, seed=None, name=\"W1\")\n",
    "# b1 = tf.random_normal([12, 1], dtype=tf.float32, seed=None, name=\"b1\")\n",
    "# W2 = tf.random_normal([6, 12], dtype=tf.float32, seed=None, name=\"W2\")\n",
    "# b2 = tf.random_normal([6, 1], dtype=tf.float32, seed=None, name=\"b2\")\n",
    "# W3 = tf.random_normal([1, 6], dtype=tf.float32, seed=None, name=\"W3\")\n",
    "# b3 = tf.random_normal([1, 1], dtype=tf.float32, seed=None, name=\"b3\")\n",
    "\n",
    "# W1 = tf.get_variable(\"W1\", [12, 9], initializer=tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "# b1 = tf.get_variable(\"b1\", [12, 1], initializer = tf.zeros_initializer())\n",
    "# W2 = tf.get_variable(\"W2\", [6, 12], initializer=tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "# b2 = tf.get_variable(\"b2\", [6, 1], initializer = tf.zeros_initializer())\n",
    "# W3 = tf.get_variable(\"W3\", [1, 6], initializer=tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "# b3 = tf.get_variable(\"b3\", [1, 1], initializer = tf.zeros_initializer())\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform([12, 9]))\n",
    "b1 = tf.Variable(tf.random_uniform([12, 1]))\n",
    "W2 = tf.Variable(tf.random_uniform([6, 12]))\n",
    "b2 = tf.Variable(tf.random_uniform([6, 1]))\n",
    "W3 = tf.Variable(tf.random_uniform([1, 6]))\n",
    "b3 = tf.Variable(tf.random_uniform([1, 1]))\n",
    "\n",
    "# W = tf.Variable(tf.random_uniform([784, 10]))\n",
    "\n",
    "Z1 = tf.add(tf.matmul(W1, X), b1)                      # Z1 = np.dot(W1, X) + b1\n",
    "A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n",
    "Z2 = tf.add(tf.matmul(W2, A1), b2)                     # Z2 = np.dot(W2, a1) + b2\n",
    "A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n",
    "Z3 = tf.add(tf.matmul(W3, A2), b3)                     # Z3 = np.dot(W3,Z2) + b3\n",
    "\n",
    "logits = Z3\n",
    "\n",
    "logits = tf.transpose(Z3)\n",
    "labels = tf.transpose(Y)\n",
    "\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels = labels, logits = logits)\n",
    "\n",
    "loss = tf.reduce_mean(entropy)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\t\n",
    "#     _, loss_test = sess.run([optimizer, loss], feed_dict={X: X_train.values.T, Y: y_train.values.reshape(1, -1)})\n",
    "#     print(loss_test)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    start_time = time.time()\n",
    "    sess.run(tf.global_variables_initializer())\t\n",
    "    n_batches = int(X_train.values.shape[1]/batch_size)\n",
    "    for i in range(n_epochs): \n",
    "        total_loss = 0\n",
    "\n",
    "        for index in range(n_batches):\n",
    "            X_batch = X_train[index*batch_size:(index+1)*batch_size].values\n",
    "            Y_batch = y_train[index*batch_size:(index+1)*batch_size].values\n",
    "            _, loss_batch = sess.run([optimizer, loss], feed_dict={X: X_batch.values.T, Y: Y_batch.values.Reshape(1, -1)})\n",
    "            print('loss_batch', loss_batch)\n",
    "            total_loss += loss_batch\n",
    "        print('Average loss epoch :{0}'.format(total_loss/n_batches))\n",
    "\n",
    "    print('Total time: {0} seconds'.format(time.time() - start_time))\n",
    "    print('loss_batch为啥都是0')\n",
    "\n",
    "    print('Optimization Finished!')\n",
    "\n",
    "    # test the model\n",
    "    n_batches = int(len(test_data)/batch_size)\n",
    "    total_correct_preds = 0\n",
    "    for index in range(n_batches):\n",
    "        X_batch = test_data[index*batch_size:(index+1)*batch_size].values\n",
    "        Y_batch = test_label[index*batch_size:(index+1)*batch_size].values\n",
    "        Y_batch = to_one_hotting(Y_batch)\n",
    "        _, loss_batch, logits_batch = sess.run([optimizer, loss, logits], feed_dict={X: X_batch, Y:Y_batch}) \n",
    "        preds = tf.nn.softmax(logits_batch)\n",
    "        correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(Y_batch, 1))\n",
    "        accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32)) # need numpy.count_nonzero(boolarr) :(\n",
    "        total_correct_preds += sess.run(accuracy)\n",
    "\n",
    "    print('Accuracy:',format(total_correct_preds/len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
