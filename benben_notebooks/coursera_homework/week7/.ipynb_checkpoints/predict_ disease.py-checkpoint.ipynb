{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import collections\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from matplotlib import pylab\n",
    "from six.moves import range\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import time\n",
    "from tf_utils import random_mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data\n",
    "url = 'https://raw.githubusercontent.com/chiphuyen/tf-stanford-tutorials/master/data/'\n",
    "\n",
    "def maybe_download(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        filename, _ = urlretrieve(url + filename, filename)\n",
    "    statinfo = os.stat(filename)\n",
    "    return filename\n",
    "\n",
    "filename = maybe_download('heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbp</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>ldl</th>\n",
       "      <th>adiposity</th>\n",
       "      <th>famhist</th>\n",
       "      <th>typea</th>\n",
       "      <th>obesity</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>age</th>\n",
       "      <th>chd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.620000e+02</td>\n",
       "      <td>4.620000e+02</td>\n",
       "      <td>4.620000e+02</td>\n",
       "      <td>4.620000e+02</td>\n",
       "      <td>4.620000e+02</td>\n",
       "      <td>4.620000e+02</td>\n",
       "      <td>4.620000e+02</td>\n",
       "      <td>4.620000e+02</td>\n",
       "      <td>4.620000e+02</td>\n",
       "      <td>462.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-2.691450e-17</td>\n",
       "      <td>-4.205390e-18</td>\n",
       "      <td>4.998407e-17</td>\n",
       "      <td>4.277483e-17</td>\n",
       "      <td>4.998407e-17</td>\n",
       "      <td>-1.826341e-17</td>\n",
       "      <td>8.026288e-17</td>\n",
       "      <td>3.172066e-17</td>\n",
       "      <td>9.612321e-19</td>\n",
       "      <td>0.346320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.751822e-01</td>\n",
       "      <td>1.472123e-01</td>\n",
       "      <td>1.443142e-01</td>\n",
       "      <td>2.176419e-01</td>\n",
       "      <td>4.933567e-01</td>\n",
       "      <td>1.510390e-01</td>\n",
       "      <td>1.321732e-01</td>\n",
       "      <td>1.663228e-01</td>\n",
       "      <td>2.981420e-01</td>\n",
       "      <td>0.476313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.190328e-01</td>\n",
       "      <td>-1.165272e-01</td>\n",
       "      <td>-2.620435e-01</td>\n",
       "      <td>-5.221463e-01</td>\n",
       "      <td>-5.844156e-01</td>\n",
       "      <td>-6.169830e-01</td>\n",
       "      <td>-3.558379e-01</td>\n",
       "      <td>-1.157986e-01</td>\n",
       "      <td>-5.676738e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.224516e-01</td>\n",
       "      <td>-1.148445e-01</td>\n",
       "      <td>-1.015906e-01</td>\n",
       "      <td>-1.575310e-01</td>\n",
       "      <td>-5.844156e-01</td>\n",
       "      <td>-9.390609e-02</td>\n",
       "      <td>-9.595711e-02</td>\n",
       "      <td>-1.123337e-01</td>\n",
       "      <td>-2.411432e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-3.698154e-02</td>\n",
       "      <td>-5.242466e-02</td>\n",
       "      <td>-2.789719e-02</td>\n",
       "      <td>1.981170e-02</td>\n",
       "      <td>4.155844e-01</td>\n",
       "      <td>-1.598402e-03</td>\n",
       "      <td>-7.500394e-03</td>\n",
       "      <td>-6.477610e-02</td>\n",
       "      <td>4.457108e-02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.267658e-02</td>\n",
       "      <td>5.975483e-02</td>\n",
       "      <td>7.314811e-02</td>\n",
       "      <td>1.628187e-01</td>\n",
       "      <td>4.155844e-01</td>\n",
       "      <td>1.060939e-01</td>\n",
       "      <td>7.695695e-02</td>\n",
       "      <td>4.652562e-02</td>\n",
       "      <td>2.486527e-01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.809672e-01</td>\n",
       "      <td>8.834728e-01</td>\n",
       "      <td>7.379565e-01</td>\n",
       "      <td>4.778537e-01</td>\n",
       "      <td>4.155844e-01</td>\n",
       "      <td>3.830170e-01</td>\n",
       "      <td>6.441621e-01</td>\n",
       "      <td>8.842014e-01</td>\n",
       "      <td>4.323262e-01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                sbp       tobacco           ldl     adiposity       famhist  \\\n",
       "count  4.620000e+02  4.620000e+02  4.620000e+02  4.620000e+02  4.620000e+02   \n",
       "mean  -2.691450e-17 -4.205390e-18  4.998407e-17  4.277483e-17  4.998407e-17   \n",
       "std    1.751822e-01  1.472123e-01  1.443142e-01  2.176419e-01  4.933567e-01   \n",
       "min   -3.190328e-01 -1.165272e-01 -2.620435e-01 -5.221463e-01 -5.844156e-01   \n",
       "25%   -1.224516e-01 -1.148445e-01 -1.015906e-01 -1.575310e-01 -5.844156e-01   \n",
       "50%   -3.698154e-02 -5.242466e-02 -2.789719e-02  1.981170e-02  4.155844e-01   \n",
       "75%    8.267658e-02  5.975483e-02  7.314811e-02  1.628187e-01  4.155844e-01   \n",
       "max    6.809672e-01  8.834728e-01  7.379565e-01  4.778537e-01  4.155844e-01   \n",
       "\n",
       "              typea       obesity       alcohol           age         chd  \n",
       "count  4.620000e+02  4.620000e+02  4.620000e+02  4.620000e+02  462.000000  \n",
       "mean  -1.826341e-17  8.026288e-17  3.172066e-17  9.612321e-19    0.346320  \n",
       "std    1.510390e-01  1.321732e-01  1.663228e-01  2.981420e-01    0.476313  \n",
       "min   -6.169830e-01 -3.558379e-01 -1.157986e-01 -5.676738e-01    0.000000  \n",
       "25%   -9.390609e-02 -9.595711e-02 -1.123337e-01 -2.411432e-01    0.000000  \n",
       "50%   -1.598402e-03 -7.500394e-03 -6.477610e-02  4.457108e-02    0.000000  \n",
       "75%    1.060939e-01  7.695695e-02  4.652562e-02  2.486527e-01    1.000000  \n",
       "max    3.830170e-01  6.441621e-01  8.842014e-01  4.323262e-01    1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre-treatment\n",
    "raw_data = pd.read_csv('heart.csv')\n",
    "\n",
    "label = raw_data['chd']\n",
    "\n",
    "data = raw_data.loc[:,raw_data.columns[:9]].replace(['Present', 'Absent'],[0, 1])\n",
    "data = data.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)), axis=0)\n",
    "\n",
    "all_data = data\n",
    "all_data['chd'] = label\n",
    "all_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paramaters for the model\n",
    "learning_rate = 0.005\n",
    "batch_size = 32\n",
    "n_epochs = 2000\n",
    "seed = 3\n",
    "threshold = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (462, 10)\n",
      "train_data shape: (369, 10)\n",
      "test_data shape: (93, 10)\n",
      "train_set shape: (9, 369)\n",
      "train_label shape: (1, 369)\n",
      "test_set shape: (9, 93)\n",
      "test_label shape: (1, 93)\n"
     ]
    }
   ],
   "source": [
    "data = all_data.values\n",
    "print(\"data shape:\", data.shape)\n",
    "\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=seed)\n",
    "print(\"train_data shape:\", train_data.shape)\n",
    "print(\"test_data shape:\", test_data.shape)\n",
    "\n",
    "train_set = train_data[:, 0:9].T\n",
    "train_label = train_data[:, 9].reshape((-1, 1)).T\n",
    "print(\"train_set shape:\", train_set.shape)\n",
    "print(\"train_label shape:\", train_label.shape)\n",
    "\n",
    "# batches = random_mini_batches(train_set, train_label, batch_size, seed)\n",
    "# print(batches[0][0].shape)\n",
    "# print(batches[0][1].shape)\n",
    "\n",
    "\n",
    "test_set = test_data[:, 0:9].T\n",
    "test_label = test_data[:, 9].reshape((-1, 1)).T\n",
    "print(\"test_set shape:\", test_set.shape)\n",
    "print(\"test_label shape:\", test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 1.586825\n",
      "Cost after epoch 100: 0.429998\n",
      "Cost after epoch 200: 0.332576\n",
      "Cost after epoch 300: 0.245787\n",
      "Cost after epoch 400: 0.181700\n",
      "Cost after epoch 500: 0.162474\n",
      "Cost after epoch 600: 0.135970\n",
      "Cost after epoch 700: 0.120020\n",
      "Cost after epoch 800: 0.090213\n",
      "Cost after epoch 900: 0.085911\n",
      "Cost after epoch 1000: 0.067222\n",
      "Cost after epoch 1100: 0.065786\n",
      "Cost after epoch 1200: 0.054789\n",
      "Cost after epoch 1300: 0.046526\n",
      "Cost after epoch 1400: 0.072974\n",
      "Cost after epoch 1500: 0.067776\n",
      "Cost after epoch 1600: 0.060148\n",
      "Cost after epoch 1700: 0.054662\n",
      "Cost after epoch 1800: 0.049053\n",
      "Cost after epoch 1900: 0.066914\n",
      "Total time: 14.820488691329956 seconds\n",
      "Optimization Finished!\n",
      "----------------------\n",
      "params: \n",
      "----------------------\n",
      "test the model:\n",
      "Train Accuracy: 0.98916\n",
      "Test Accuracy: 0.623656\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(dtype = np.float32, shape = [9, None])\n",
    "Y = tf.placeholder(dtype = np.float32, shape = [1, None])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([20, 9]), name='W1')\n",
    "b1 = tf.Variable(tf.random_normal([20, 1]), name='b1')\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([10, 20]), name='W2')\n",
    "b2 = tf.Variable(tf.random_normal([10, 1]), name='b2')\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([1, 10]), name='W3')\n",
    "b3 = tf.Variable(tf.random_normal([1, 1]), name='b3')\n",
    "\n",
    "Z1 = tf.add(tf.matmul(W1, X), b1) \n",
    "A1 = tf.nn.relu(Z1)\n",
    "Z2 = tf.add(tf.matmul(W2, A1), b2) \n",
    "A2 = tf.nn.relu(Z2)\n",
    "logits = tf.add(tf.matmul(W3, A2), b3) \n",
    "\n",
    "entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels = Y, logits = logits)\n",
    "\n",
    "cost = tf.reduce_mean(entropy)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "costs = []\n",
    "with tf.Session() as sess:\n",
    "    merged_summary_op = tf.summary.merge_all()\n",
    "    summary_writer = tf.summary.FileWriter('../tmp', sess.graph)\n",
    "    start_time = time.time()\n",
    "    sess.run(tf.global_variables_initializer())\t\n",
    "\n",
    "    for epoch in range(n_epochs): \n",
    "        epoch_cost = 0        \n",
    "        n_batches = int(train_set.shape[1]/batch_size)\n",
    "        seed = seed + 1\n",
    "        minibatches = random_mini_batches(train_set, train_label, batch_size, seed)\n",
    "        \n",
    "        for minibatch in minibatches:\n",
    "            (minibatch_X, minibatch_Y) = minibatch\n",
    "\n",
    "            _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "\n",
    "            epoch_cost += minibatch_cost / n_batches\n",
    "\n",
    "        # Print the cost every epoch\n",
    "        if epoch % 100 == 0:\n",
    "            print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "        if epoch % 5 == 0:\n",
    "            costs.append(epoch_cost)\n",
    "\n",
    "    print('Total time: {0} seconds'.format(time.time() - start_time))\n",
    "    print('Optimization Finished!')\n",
    "    print('----------------------')\n",
    "    \n",
    "    print('params: ')\n",
    "    \n",
    "    W1 = sess.run(W1)\n",
    "    b1 = sess.run(b1)\n",
    "    W2 = sess.run(W2)\n",
    "    b2 = sess.run(b2)\n",
    "    W3 = sess.run(W3)\n",
    "    b3 = sess.run(b3)\n",
    "    \n",
    "#     print('W1', sess.run(W1))\n",
    "#     print('b1', sess.run(b1))\n",
    "#     print('W2', sess.run(W2))\n",
    "#     print('b2', sess.run(b2))\n",
    "#     print('W3', sess.run(W3))\n",
    "#     print('b3', sess.run(b3))\n",
    "    print('----------------------')\n",
    "    \n",
    "    print('test the model:')\n",
    "    \n",
    "    result = tf.cast(tf.greater(logits, threshold), \"float\")\n",
    "    correct_prediction = tf.equal(result , Y)\n",
    "\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "    print (\"Train Accuracy:\", accuracy.eval({X: train_set, Y: train_label}))\n",
    "    print (\"Test Accuracy:\", accuracy.eval({X: test_set, Y: test_label}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
