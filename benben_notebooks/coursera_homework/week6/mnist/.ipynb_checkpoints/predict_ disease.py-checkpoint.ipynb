{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import collections\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from matplotlib import pylab\n",
    "from six.moves import range\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# download data\n",
    "url = 'https://raw.githubusercontent.com/chiphuyen/tf-stanford-tutorials/master/data/'\n",
    "\n",
    "def maybe_download(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        filename, _ = urlretrieve(url + filename, filename)\n",
    "    statinfo = os.stat(filename)\n",
    "    return filename\n",
    "\n",
    "filename = maybe_download('heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                sbp       tobacco           ldl     adiposity       famhist  \\\n",
      "count  4.620000e+02  4.620000e+02  4.620000e+02  4.620000e+02  4.620000e+02   \n",
      "mean  -2.691450e-17 -4.205390e-18  4.998407e-17  4.277483e-17  4.998407e-17   \n",
      "std    1.751822e-01  1.472123e-01  1.443142e-01  2.176419e-01  4.933567e-01   \n",
      "min   -3.190328e-01 -1.165272e-01 -2.620435e-01 -5.221463e-01 -5.844156e-01   \n",
      "25%   -1.224516e-01 -1.148445e-01 -1.015906e-01 -1.575310e-01 -5.844156e-01   \n",
      "50%   -3.698154e-02 -5.242466e-02 -2.789719e-02  1.981170e-02  4.155844e-01   \n",
      "75%    8.267658e-02  5.975483e-02  7.314811e-02  1.628187e-01  4.155844e-01   \n",
      "max    6.809672e-01  8.834728e-01  7.379565e-01  4.778537e-01  4.155844e-01   \n",
      "\n",
      "              typea       obesity       alcohol           age         chd  \n",
      "count  4.620000e+02  4.620000e+02  4.620000e+02  4.620000e+02  462.000000  \n",
      "mean  -1.826341e-17  8.026288e-17  3.172066e-17  9.612321e-19    0.346320  \n",
      "std    1.510390e-01  1.321732e-01  1.663228e-01  2.981420e-01    0.476313  \n",
      "min   -6.169830e-01 -3.558379e-01 -1.157986e-01 -5.676738e-01    0.000000  \n",
      "25%   -9.390609e-02 -9.595711e-02 -1.123337e-01 -2.411432e-01    0.000000  \n",
      "50%   -1.598402e-03 -7.500394e-03 -6.477610e-02  4.457108e-02    0.000000  \n",
      "75%    1.060939e-01  7.695695e-02  4.652562e-02  2.486527e-01    1.000000  \n",
      "max    3.830170e-01  6.441621e-01  8.842014e-01  4.323262e-01    1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Pre-treatment\n",
    "raw_data = pd.read_csv('heart.csv')\n",
    "\n",
    "\n",
    "label = raw_data['chd']\n",
    "\n",
    "data = raw_data.loc[:,raw_data.columns[:9]].replace(['Present', 'Absent'],[0, 1])\n",
    "data = data.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)), axis=0)\n",
    "\n",
    "all_data = data\n",
    "all_data['chd'] = label\n",
    "print(all_data.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              sbp     tobacco         ldl   adiposity     famhist       typea  \\\n",
      "count  320.000000  320.000000  320.000000  320.000000  320.000000  320.000000   \n",
      "mean     0.002041    0.016838    0.007797    0.002336   -0.037541    0.006430   \n",
      "std      0.177675    0.160045    0.146995    0.220087    0.498578    0.155772   \n",
      "min     -0.310486   -0.116527   -0.262044   -0.468440   -0.584416   -0.616983   \n",
      "25%     -0.122452   -0.108114   -0.094970   -0.159909   -0.584416   -0.093906   \n",
      "50%     -0.036982   -0.033194   -0.014657    0.025126    0.415584    0.013786   \n",
      "75%      0.082677    0.076582    0.079768    0.170371    0.415584    0.106094   \n",
      "max      0.680967    0.883473    0.737956    0.477854    0.415584    0.383017   \n",
      "\n",
      "          obesity     alcohol         age         chd  \n",
      "count  320.000000  320.000000  320.000000  320.000000  \n",
      "mean    -0.001923    0.000260    0.023972    0.500000  \n",
      "std      0.129342    0.170825    0.294980    0.500783  \n",
      "min     -0.355838   -0.115799   -0.567674    0.000000  \n",
      "25%     -0.094075   -0.112334   -0.200327    0.000000  \n",
      "50%     -0.004677   -0.063757    0.064979    0.500000  \n",
      "75%      0.078133    0.035723    0.269061    1.000000  \n",
      "max      0.617186    0.884201    0.432326    1.000000  \n"
     ]
    }
   ],
   "source": [
    "#重组数据集，保证label数量相等\n",
    "one_label_result = all_data[(all_data.chd == 1)]\n",
    "zero_label_result = all_data[(all_data.chd == 0)]\n",
    "\n",
    "one_label_length = len(one_label_result)\n",
    "zero_label_length = len(zero_label_result)\n",
    "\n",
    "small_len = one_label_length if one_label_length < zero_label_length else zero_label_length;\n",
    "\n",
    "\n",
    "one_index = random.sample(list(one_label_result.index.values), small_len)\n",
    "zero_index = random.sample(list(zero_label_result.index.values), small_len)\n",
    "\n",
    "new_data = pd.concat([one_label_result.ix[one_index], zero_label_result.ix[zero_index]])\n",
    "print(new_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 数据分10份，拿一份做测试集，九份做训练集\n",
    "train_data_size = int(small_len * 2 * 0.9)\n",
    "test_data_size = int(small_len * 2 * 0.1)\n",
    "\n",
    "train_data_index = random.sample(list(new_data.index.values), train_data_size)\n",
    "train_data = new_data.ix[train_data_index]\n",
    "\n",
    "test_data_index = list(set(new_data.index.values).difference(set(train_data_index)))\n",
    "test_data = new_data.ix[test_data_index]\n",
    "\n",
    "train_label = train_data['chd']\n",
    "train_data = train_data.loc[:,raw_data.columns[:9]]\n",
    "\n",
    "test_label = test_data['chd']\n",
    "test_data = test_data.loc[:,raw_data.columns[:9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define paramaters for the model\n",
    "learning_rate = 0.01\n",
    "batch_size = 16\n",
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 0.0\n",
      "1 : 0.0\n",
      "2 : 0.0\n",
      "3 : 0.0\n",
      "4 : 0.0\n",
      "5 : 0.0\n",
      "6 : 0.0\n",
      "7 : 0.0\n",
      "8 : 0.0\n",
      "9 : 0.0\n",
      "10 : 0.0\n",
      "11 : 0.0\n",
      "12 : 0.0\n",
      "13 : 0.0\n",
      "14 : 0.0\n",
      "15 : 0.0\n",
      "16 : 0.0\n",
      "17 : 0.0\n",
      "Average loss epoch :0.0\n",
      "0 : 0.0\n",
      "1 : 0.0\n",
      "2 : 0.0\n",
      "3 : 0.0\n",
      "4 : 0.0\n",
      "5 : 0.0\n",
      "6 : 0.0\n",
      "7 : 0.0\n",
      "8 : 0.0\n",
      "9 : 0.0\n",
      "10 : 0.0\n",
      "11 : 0.0\n",
      "12 : 0.0\n",
      "13 : 0.0\n",
      "14 : 0.0\n",
      "15 : 0.0\n",
      "16 : 0.0\n",
      "17 : 0.0\n",
      "Average loss epoch :0.0\n",
      "0 : 0.0\n",
      "1 : 0.0\n",
      "2 : 0.0\n",
      "3 : 0.0\n",
      "4 : 0.0\n",
      "5 : 0.0\n",
      "6 : 0.0\n",
      "7 : 0.0\n",
      "8 : 0.0\n",
      "9 : 0.0\n",
      "10 : 0.0\n",
      "11 : 0.0\n",
      "12 : 0.0\n",
      "13 : 0.0\n",
      "14 : 0.0\n",
      "15 : 0.0\n",
      "16 : 0.0\n",
      "17 : 0.0\n",
      "Average loss epoch :0.0\n",
      "0 : 0.0\n",
      "1 : 0.0\n",
      "2 : 0.0\n",
      "3 : 0.0\n",
      "4 : 0.0\n",
      "5 : 0.0\n",
      "6 : 0.0\n",
      "7 : 0.0\n",
      "8 : 0.0\n",
      "9 : 0.0\n",
      "10 : 0.0\n",
      "11 : 0.0\n",
      "12 : 0.0\n",
      "13 : 0.0\n",
      "14 : 0.0\n",
      "15 : 0.0\n",
      "16 : 0.0\n",
      "17 : 0.0\n",
      "Average loss epoch :0.0\n",
      "0 : 0.0\n",
      "1 : 0.0\n",
      "2 : 0.0\n",
      "3 : 0.0\n",
      "4 : 0.0\n",
      "5 : 0.0\n",
      "6 : 0.0\n",
      "7 : 0.0\n",
      "8 : 0.0\n",
      "9 : 0.0\n",
      "10 : 0.0\n",
      "11 : 0.0\n",
      "12 : 0.0\n",
      "13 : 0.0\n",
      "14 : 0.0\n",
      "15 : 0.0\n",
      "16 : 0.0\n",
      "17 : 0.0\n",
      "Average loss epoch :0.0\n",
      "0 : 0.0\n",
      "1 : 0.0\n",
      "2 : 0.0\n",
      "3 : 0.0\n",
      "4 : 0.0\n",
      "5 : 0.0\n",
      "6 : 0.0\n",
      "7 : 0.0\n",
      "8 : 0.0\n",
      "9 : 0.0\n",
      "10 : 0.0\n",
      "11 : 0.0\n",
      "12 : 0.0\n",
      "13 : 0.0\n",
      "14 : 0.0\n",
      "15 : 0.0\n",
      "16 : 0.0\n",
      "17 : 0.0\n",
      "Average loss epoch :0.0\n",
      "0 : 0.0\n",
      "1 : 0.0\n",
      "2 : 0.0\n",
      "3 : 0.0\n",
      "4 : 0.0\n",
      "5 : 0.0\n",
      "6 : 0.0\n",
      "7 : 0.0\n",
      "8 : 0.0\n",
      "9 : 0.0\n",
      "10 : 0.0\n",
      "11 : 0.0\n",
      "12 : 0.0\n",
      "13 : 0.0\n",
      "14 : 0.0\n",
      "15 : 0.0\n",
      "16 : 0.0\n",
      "17 : 0.0\n",
      "Average loss epoch :0.0\n",
      "0 : 0.0\n",
      "1 : 0.0\n",
      "2 : 0.0\n",
      "3 : 0.0\n",
      "4 : 0.0\n",
      "5 : 0.0\n",
      "6 : 0.0\n",
      "7 : 0.0\n",
      "8 : 0.0\n",
      "9 : 0.0\n",
      "10 : 0.0\n",
      "11 : 0.0\n",
      "12 : 0.0\n",
      "13 : 0.0\n",
      "14 : 0.0\n",
      "15 : 0.0\n",
      "16 : 0.0\n",
      "17 : 0.0\n",
      "Average loss epoch :0.0\n",
      "0 : 0.0\n",
      "1 : 0.0\n",
      "2 : 0.0\n",
      "3 : 0.0\n",
      "4 : 0.0\n",
      "5 : 0.0\n",
      "6 : 0.0\n",
      "7 : 0.0\n",
      "8 : 0.0\n",
      "9 : 0.0\n",
      "10 : 0.0\n",
      "11 : 0.0\n",
      "12 : 0.0\n",
      "13 : 0.0\n",
      "14 : 0.0\n",
      "15 : 0.0\n",
      "16 : 0.0\n",
      "17 : 0.0\n",
      "Average loss epoch :0.0\n",
      "0 : 0.0\n",
      "1 : 0.0\n",
      "2 : 0.0\n",
      "3 : 0.0\n",
      "4 : 0.0\n",
      "5 : 0.0\n",
      "6 : 0.0\n",
      "7 : 0.0\n",
      "8 : 0.0\n",
      "9 : 0.0\n",
      "10 : 0.0\n",
      "11 : 0.0\n",
      "12 : 0.0\n",
      "13 : 0.0\n",
      "14 : 0.0\n",
      "15 : 0.0\n",
      "16 : 0.0\n",
      "17 : 0.0\n",
      "Average loss epoch :0.0\n",
      "Total time: 0.6974973678588867 seconds\n",
      "loss_batch为啥都是0\n",
      "Optimization Finished!\n",
      "Accuracy: 1.0\n",
      "写完想哭，我去看答案了\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(dtype = np.float32, shape = [batch_size, 9], name='X')\n",
    "Y = tf.placeholder(dtype = np.float32, shape = [batch_size, 1], name='Y')\n",
    "\n",
    "W = tf.Variable(tf.random_normal([9, 1]), name='W')\n",
    "b = tf.Variable(tf.random_normal([batch_size, 1]), name='b')\n",
    "\n",
    "logits = tf.matmul(X, W) + b\n",
    "\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits(labels = Y, logits = logits)\n",
    "\n",
    "loss = tf.reduce_mean(entropy)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    start_time = time.time()\n",
    "    sess.run(tf.global_variables_initializer())\t\n",
    "    n_batches = int(len(train_data)/batch_size)\n",
    "    for i in range(n_epochs): \n",
    "        total_loss = 0\n",
    "\n",
    "        for index in range(n_batches):\n",
    "            X_batch = train_data[index*batch_size:(index+1)*batch_size].values\n",
    "            Y_batch = np.mat(train_label[index*batch_size:(index+1)*batch_size].values).T\n",
    "            _, loss_batch = sess.run([optimizer, loss], feed_dict={X: X_batch, Y: Y_batch})\n",
    "\n",
    "            print(index, ':', loss_batch)\n",
    "            \n",
    "            total_loss += loss_batch\n",
    "        print('Average loss epoch :{0}'.format(total_loss/n_batches))\n",
    "\n",
    "    print('Total time: {0} seconds'.format(time.time() - start_time))\n",
    "    print('loss_batch为啥都是0')\n",
    "#     print('b:',b.eval())\n",
    "#     print('W:',W.eval())\n",
    "\n",
    "    print('Optimization Finished!')\n",
    "\n",
    "    # test the model\n",
    "    n_batches = int(len(test_data)/batch_size)\n",
    "    total_correct_preds = 0\n",
    "    for index in range(n_batches):\n",
    "        X_batch = test_data[index*batch_size:(index+1)*batch_size].values\n",
    "        Y_batch = np.mat(test_label[index*batch_size:(index+1)*batch_size].values).T\n",
    "        _, loss_batch, logits_batch = sess.run([optimizer, loss, logits], feed_dict={X: X_batch, Y:Y_batch}) \n",
    "        preds = tf.nn.softmax(logits_batch)\n",
    "        correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(Y_batch, 1))\n",
    "        accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32)) # need numpy.count_nonzero(boolarr) :(\n",
    "        total_correct_preds += sess.run(accuracy)\n",
    "\n",
    "    print('Accuracy:',format(total_correct_preds/len(test_data)))\n",
    "    print('写完想哭，我去看答案了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
